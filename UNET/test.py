import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import glob
from tqdm import tqdm
import numpy as np
import matplotlib.pyplot as plt
import os
from PIL import Image
from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_score, recall_score, jaccard_score

# ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®æŸ”è»Ÿãªè¨˜è¿°ã‚’ä½¿ç”¨
try:
    # è¨“ç·´æ™‚ã®ãƒ¢ãƒ‡ãƒ«å®šç¾©ãŒ 'UNET/model.py' ã«ã‚ã‚‹ã¨ä»®å®š
    from UNET.model import UNet
except ImportError:
    # ã¾ãŸã¯ã€ç¾åœ¨ã®å®Ÿè¡Œãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚ã‚‹ 'model.py' ã«ã‚ã‚‹ã¨ä»®å®š
    from model import UNet

# ==============================================================================
# 0. ãƒ‘ã‚¹ã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š
# ==============================================================================
# ğŸ“ å¿…è¦ã«å¿œã˜ã¦ãƒ‘ã‚¹ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„
CHECKPOINT_PATH = './UNET/checkpoints/best_model.pth' 
DATA_DIR = './UNET/Data'
BATCH_SIZE = 2
# åˆ©ç”¨å¯èƒ½ãªå ´åˆã¯GPUã‚’ä½¿ç”¨
if torch.cuda.is_available():
    DEVICE = 'cuda'
elif torch.backends.mps.is_available():
    DEVICE = 'mps'
else:
    DEVICE = 'cpu'

# ==========================================
# 2. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹ (å­¦ç¿’ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ãã®ã¾ã¾æµç”¨)
# ==========================================
class NpyDataset(Dataset):
    def __init__(self, root_dir, split='train'):
        self.img_dir = os.path.join(root_dir, split, 'images')
        self.lbl_dir = os.path.join(root_dir, split, 'labels')
        self.split = split
        
        self.img_files = sorted(glob.glob(os.path.join(self.img_dir, '*.npy')))
        self.lbl_files = sorted(glob.glob(os.path.join(self.lbl_dir, '*.npy')))
        
        assert len(self.img_files) == len(self.lbl_files), \
            f"File mismatch: {len(self.img_files)} vs {len(self.lbl_files)}"

    def __len__(self):
        return len(self.img_files)

    def __getitem__(self, idx):
        img_path = self.img_files[idx]
        lbl_path = self.lbl_files[idx]
        
        img_arr = np.load(img_path).astype(np.float32) # (H, W, C)
        lbl_arr = np.load(lbl_path).astype(np.float32) # (H, W, C)

        # ---------------------------------------------
        # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®é©ç”¨ (trainæ™‚ã®ã¿)
        # 
        # å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ:
        # - ç”»åƒã¨ãƒ©ãƒ™ãƒ«ã«åŒã˜å¤‰æ›ã‚’é©ç”¨ã™ã‚‹
        # - ç”»åƒã«ã¯INTER_LINEARã€ãƒ©ãƒ™ãƒ«ã«ã¯INTER_NEARESTã‚’ä½¿ç”¨
        # - æ¬¡å…ƒãŒå¤±ã‚ã‚ŒãŸå ´åˆã¯expand_dimsã§å¾©å…ƒ
        # ---------------------------------------------
        if self.split == 'train':
            # WRITE ME: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’å®Ÿè£…
            pass

        # (H, W, C) -> (C, H, W)
        img_tensor = torch.from_numpy(img_arr).permute(2, 0, 1)
        lbl_tensor = torch.from_numpy(lbl_arr).permute(2, 0, 1)
        
        return img_tensor, lbl_tensor

# ==========================================
# 3. è©•ä¾¡ãƒ­ã‚¸ãƒƒã‚¯ (ä¿®æ­£ç‰ˆ)
# ==========================================
def jaccard_index(pred_mask, true_mask, smooth=1e-5):
    """ç”»åƒ1æšã”ã¨ã®IoUã‚’è¨ˆç®—ã™ã‚‹"""
    intersection = (pred_mask * true_mask).sum()
    union = pred_mask.sum() + true_mask.sum() - intersection
    return (intersection + smooth) / (union + smooth)

def evaluate_model(model, data_loader, device, iou_threshold=0.5):
    model.eval()
    
    # ğŸš¨ ç—‡ä¾‹å˜ä½ã®ROC/AUCè¨ˆç®—ç”¨ã®ãƒªã‚¹ãƒˆ (ä¿®æ­£ç®‡æ‰€) ğŸš¨
    all_scores_img = []   # ç”»åƒã”ã¨ã®ã‚¹ã‚³ã‚¢ (æœ€å¤§äºˆæ¸¬ç¢ºç‡ã‚’ä½¿ç”¨)
    all_targets_img = []  # ç”»åƒã”ã¨ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ (ç•°å¸¸ã®æœ‰ç„¡)
    
    # ç—‡ä¾‹å˜ä½ã®æ··åˆè¡Œåˆ—ã‚«ã‚¦ãƒ³ãƒˆç”¨
    true_positives_img = 0
    false_positives_img = 0
    false_negatives_img = 0
    true_negatives_img = 0
    total_images = 0

    with torch.no_grad():
        for inputs, targets, _ in tqdm(data_loader, desc="Eval "):
            inputs = inputs.to(device)
            targets = targets.to(device) # [B, 1, H, W]

            outputs = model(inputs)
            probs = torch.sigmoid(outputs) 
            preds_binary = (probs > 0.5).float() # [B, 1, H, W]
            

            for i in range(inputs.size(0)):
                pred_mask = preds_binary[i].squeeze()
                true_mask = targets[i].squeeze()
                prob_map = probs[i].squeeze() # ç¢ºç‡ãƒãƒƒãƒ—

                # --- 1. ROC/AUCç”¨ã®ã‚¹ã‚³ã‚¢ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’æŠ½å‡º (ç—‡ä¾‹å˜ä½) ---
                has_positive_target = true_mask.sum() > 0 # ç”»åƒã«ç•°å¸¸ãŒã‚ã‚‹ã‹ (ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ)
                
                # ã‚¹ã‚³ã‚¢ã¨ã—ã¦ã€ç”»åƒå†…ã®æœ€å¤§äºˆæ¸¬ç¢ºç‡ã‚’ä½¿ç”¨
                # ç•°å¸¸ã®å­˜åœ¨ã«å¯¾ã™ã‚‹ç¢ºä¿¡åº¦ãŒé«˜ã„ã»ã©ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚‹
                score_img = prob_map.max().item() 
                
                all_scores_img.append(score_img)
                all_targets_img.append(1 if has_positive_target else 0)

                # --- 2. IoUåŸºæº–ã®æ··åˆè¡Œåˆ—è¨ˆç®— (å¤‰æ›´ãªã—) ---
                iou = jaccard_index(pred_mask, true_mask)
                has_positive_pred = pred_mask.sum() > 0

                if iou >= iou_threshold:
                    if has_positive_target:
                        true_positives_img += 1 
                    else:
                        true_negatives_img += 1 
                else:
                    if has_positive_target:
                        false_negatives_img += 1 
                    elif has_positive_pred:
                        false_positives_img += 1 
                    # else: ä¸¡æ–¹ãªã—ï¼†IoUä½ã¯ã‚¹ã‚­ãƒƒãƒ—
                
                total_images += 1

    # --- è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®— ---
    
    # IoUåŸºæº–ã®æ··åˆè¡Œåˆ— (Image-wise)
    # ... (æ··åˆè¡Œåˆ—ã®è¨ˆç®—ã¯å¤‰æ›´ãªã—) ...
    tp, fp, fn, tn = true_positives_img, false_positives_img, false_negatives_img, true_negatives_img
    precision_img = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall_img = tp / (tp + fn) if (tp + fn) > 0 else 0

    # ğŸš¨ ROC/AUC (ç—‡ä¾‹å˜ä½ã®ã‚¹ã‚³ã‚¢ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’ä½¿ç”¨) ğŸš¨
    targets_np_img = np.array(all_targets_img)
    scores_np_img = np.array(all_scores_img)
    
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãŒå˜ä¸€ã‚¯ãƒ©ã‚¹ã®ã¿ã®å ´åˆã®ä¾‹å¤–å‡¦ç†
    if len(np.unique(targets_np_img)) > 1:
        fpr, tpr, _ = roc_curve(targets_np_img, scores_np_img)
        roc_auc = auc(fpr, tpr)
    else:
        # å…¨ç—‡ä¾‹ãŒåŒã˜ã‚¯ãƒ©ã‚¹ã®å ´åˆ
        fpr, tpr, roc_auc = np.array([0, 1]), np.array([0, 1]), 0.5
    
    metrics = {
        "IoU (Pixel Avg, Reference)": 0.0, # ãƒ”ã‚¯ã‚»ãƒ«IoUã¯ä¸è¦ã®ãŸã‚çœç•¥ã¾ãŸã¯0
        "CM (Image-wise)": np.array([[tn, fp], [fn, tp]]),
        "TN_img": tn, "FP_img": fp, "FN_img": fn, "TP_img": tp,
        "Precision (Image)": precision_img,
        "Recall (Image)": recall_img,
        "Total Images": total_images,
        "ROC Curve (FPR, TPR)": (fpr, tpr),
        "AUC (Image-wise)": roc_auc # é …ç›®åã‚’å¤‰æ›´
    }
    return metrics

# --- ROCæ›²ç·šãƒ—ãƒ­ãƒƒãƒˆ ---
def plot_roc_curve(fpr, tpr, roc_auc):
    plt.figure()
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate (FPR)'); plt.ylabel('True Positive Rate (TPR)')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc="lower right"); plt.grid(True); plt.show()

# --- ãƒ©ãƒ™ãƒ«ã¨äºˆæ¸¬ã®ä¸¦åˆ—ç”»åƒãƒ—ãƒ­ãƒƒãƒˆ ---
def plot_predictions(model, dataset, device, num_images=5):
    fig, axes = plt.subplots(num_images, 3, figsize=(12, num_images * 4))
    
    for i in range(num_images):
        img_tensor, mask_tensor, filename = dataset[i]
        input_img = img_tensor.unsqueeze(0).to(device) # ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ 
        
        with torch.no_grad():
            output_logit = model(input_img)
            # ç¢ºç‡ã«å¤‰æ›ã—ã€CPUã«æˆ»ã—ã¦numpyã« [H, W]
            pred_prob = torch.sigmoid(output_logit).squeeze().cpu().numpy()
        
        # ç”»åƒè¡¨ç¤ºç”¨ã®numpyé…åˆ— [H, W, C]
        img_np = img_tensor.cpu().numpy().transpose(1, 2, 0)
        true_mask_np = mask_tensor.squeeze().cpu().numpy() # [H, W]
        pred_binary_np = (pred_prob > 0.5).astype(np.float32) # [H, W]

        # 1ãƒãƒ£ãƒ³ãƒãƒ«ç”»åƒã‚’ã‚«ãƒ©ãƒ¼ã§è¡¨ç¤ºã™ã‚‹ãŸã‚ã€å¿…è¦ã§ã‚ã‚Œã°squeeze()
        if img_np.shape[2] == 1:
            img_np = img_np.squeeze(axis=2)
        # 1åˆ—ç›®: å…ƒç”»åƒ
        axes[i, 0].imshow(img_np, cmap='gray' if img_np.ndim == 2 else None)
        axes[i, 0].set_title(f'Original Image\n({filename})')
        axes[i, 0].axis('off')

        # 2åˆ—ç›®: æ­£è§£ãƒ©ãƒ™ãƒ«
        axes[i, 1].imshow(true_mask_np, cmap='gray')
        axes[i, 1].set_title('True Label (Mask)')
        axes[i, 1].axis('off')

        # 3åˆ—ç›®: äºˆæ¸¬ãƒã‚¹ã‚¯
        axes[i, 2].imshow(pred_binary_np, cmap='gray')
        axes[i, 2].set_title('Predicted Mask')
        axes[i, 2].axis('off')

    plt.tight_layout()
    plt.show()

# ==========================================
# 4. ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ–ãƒ­ãƒƒã‚¯
# ==========================================
def main():
    print(f"Using Device: {DEVICE}")

    # Testãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ­ãƒ¼ãƒ‰ (split='test'ã‚’æŒ‡å®š)
    test_dataset = NpyDataset(DATA_DIR, split='test')
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)
    
    print(f"Using Device: {DEVICE}")

    test_dataset = NpyDataset(DATA_DIR, split='test')
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)
    
    print(f"Test Data: {len(test_dataset)}")

    if len(test_dataset) == 0:
        print("âŒ Error: Test Data is empty. Check your DATA_DIR path and file structure.")
        print(f"Expected files in: {os.path.join(DATA_DIR, 'test', 'images')} and labels.")
        return

    # ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã¨ãƒ­ãƒ¼ãƒ‰ (çœç•¥)
    try:
        model = UNet(n_channels=1, n_classes=1).to(DEVICE)
        model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))
        model.eval()
        print(f"âœ… Model loaded from: {CHECKPOINT_PATH}")
    except Exception as e:
        print(f"âŒ Error loading model: {e}"); return

    # è©•ä¾¡ã®å®Ÿè¡Œ
    print("\nğŸ”¬ Starting evaluation on Test Data (Image-wise CM, IoU Thresh=0.5)...")
    metrics = evaluate_model(model, test_loader, DEVICE)
    
    # çµæœã®è¡¨ç¤º
    print("\n" + "="*50)
    print("      Segmentation Model Evaluation Metrics")
    print("          (IoU Threshold: 0.5)")
    print("="*50)
    print(f"Total Images: {metrics['Total Images']}")
    print(f"AUC (Image-wise, Max Prob): {metrics['AUC (Image-wise)']:.4f}") # é …ç›®åã‚’ä¿®æ­£
    
    print("\n--- Confusion Matrix (Image-wise, by IoU) ---")
    print(f"True Positives (TP): {metrics['TP_img']}")
    print(f"False Positives (FP): {metrics['FP_img']}")
    print(f"False Negatives (FN): {metrics['FN_img']}")
    print(f"True Negatives (TN): {metrics['TN_img']}")
    print("---------------------------------------------")
    print(f"Precision (é©åˆç‡): {metrics['Precision (Image)']:.4f}")
    print(f"Recall (å†ç¾ç‡): {metrics['Recall (Image)']:.4f}")

    # ROCæ›²ç·šã®ãƒ—ãƒ­ãƒƒãƒˆ
    plot_roc_curve(metrics["ROC Curve (FPR, TPR)"][0], metrics["ROC Curve (FPR, TPR)"][1], metrics['AUC (Image-wise)'])
    
    # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã¨äºˆæ¸¬ã®è¦–è¦šåŒ–
    print("\nğŸ–¼ï¸ Displaying sample predictions...")
    num_to_plot = min(5, len(test_dataset)) 
    plot_predictions(model, test_dataset, DEVICE, num_images=num_to_plot)

if __name__ == "__main__":
    main()
